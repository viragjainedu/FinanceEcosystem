{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39be841a965a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# some other library are imported along with the code\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "# to avoid warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_colwidth', 1000, 'display.max_rows', None, 'display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/99/f0/f99700ef327e51d291efdf4a6de29e685c4d198cbf8531541fc84d169e0e/pandas-1.3.5.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/50/46/292cff79f5b30151b027400efdb3f740ea03271b600751b6696cf550c10d/numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting pytz>=2017.3 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/e3/d9f046b5d1c94a3aeab15f1f867aa414f8ee9d196fae6865f1d6a0ee1a0b/pytz-2021.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /snap/jupyter/6/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /snap/jupyter/6/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\n",
      "Building wheels for collected packages: pandas\n",
      "  Building wheel for pandas (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Complete output from command /snap/jupyter/6/bin/python /snap/jupyter/6/lib/python3.7/site-packages/pip/_vendor/pep517/_in_process.py build_wheel /tmp/tmp1aur_8qj:\u001b[0m\n",
      "\u001b[31m  ERROR: running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  running egg_info\n",
      "  writing pandas.egg-info/PKG-INFO\n",
      "  writing dependency_links to pandas.egg-info/dependency_links.txt\n",
      "  writing entry points to pandas.egg-info/entry_points.txt\n",
      "  writing requirements to pandas.egg-info/requires.txt\n",
      "  writing top-level names to pandas.egg-info/top_level.txt\n",
      "  reading manifest file 'pandas.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  no previously-included directories found matching 'doc/build'\n",
      "  warning: no previously-included files matching '*.bz2' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.csv' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.dta' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.feather' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.tar' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.gz' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.h5' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.html' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.json' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.jsonl' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.msgpack' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pdf' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pickle' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.png' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pptx' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.ods' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.odt' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.orc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.sas7bdat' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.sav' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.xls' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.xlsb' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.xlsm' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.xlsx' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.xpt' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.xz' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.zip' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "  warning: no previously-included files matching '#*' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.py[ocd]' found anywhere in distribution\n",
      "  no previously-included directories found matching 'pandas/tests/io/parser/data'\n",
      "  adding license file 'LICENSE'\n",
      "  UPDATING build/lib.linux-x86_64-3.7/pandas/_version.py\n",
      "  set build/lib.linux-x86_64-3.7/pandas/_version.py to '1.3.5'\n",
      "  running build_ext\n",
      "  building 'pandas._libs.algos' extension\n",
      "  error: command 'gcc' failed: No such file or directory: 'gcc'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for pandas\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for pandas\n",
      "Failed to build pandas\n",
      "\u001b[31mERROR: Could not build wheels for pandas which use PEP 517 and cannot be installed directly\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data we saved from the first notebook part 1 \n",
    "loans_2007_2019 = pd.read_csv('loans_2007_2019_cleaned.csv')\n",
    "\n",
    "# view 1th rows\n",
    "display(loans_2007_2019.head(1))\n",
    "\n",
    "print('The total number of rows and columns in our cleaned 2007 to 2019 loan data is: ',loans_2007_2019.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read investment data made from part 1.\n",
    "investment = pd.read_csv('investment.csv')\n",
    "# add loan grade column\n",
    "investment['loan_grade']=['A','B','C','D','E','F','G'] # since I saved the data as index=False, so i need to add it back.\n",
    "# view the table\n",
    "investment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: From part 1, we have found the proportion of the loans between different grade are not the same, and I also mentioned that 'Charged-Off' rate does NOT mean the when the loans are charged off, investor will loss all the principal and interest, because loan payment schedul is a mortgage-like arrangement and a loan maybe charged off during the loan term. This can explain why the charged-off rate is even higher than interest rate except for A loans.\n",
    "\n",
    "From first row, we can see if an investor put 25 dollar per loan and invest in 1000 loan, and ONLY choose A loans to invest, the average expected return is 7.1%, but if he/she lose all the money for the loans that are charged-off, the net return is: 0.071004-0.059498 = 1.5%. We can also calculate as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the worst case for expected return \n",
    "((0.073353-0.059693)*25*1000)/(25*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric(model, X_test, y_test):\n",
    "    \n",
    "    # getting predicted values\n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    # False positives\n",
    "    fp_filter = (y_predict == 1) & (y_test == 0)\n",
    "    fp = len(y_predict[fp_filter])\n",
    "    \n",
    "    # True positives.\n",
    "    tp_filter = (y_predict == 1) & (y_test == 1)\n",
    "    tp = len(y_predict[tp_filter])\n",
    "    \n",
    "    # False negatives.\n",
    "    fn_filter = (y_predict == 0) & (y_test == 1)\n",
    "    fn = len(y_predict[fn_filter])\n",
    "    \n",
    "    # True negatives\n",
    "    tn_filter = (y_predict == 0) & (y_test == 0)\n",
    "    tn = len(y_predict[tn_filter])\n",
    "    \n",
    "    # Rates\n",
    "    tpr = tp  / (tp + fn)\n",
    "    fpr = fp  / (fp + tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    \n",
    "    print('Confusion matrix: \\n', confusion_matrix(y_test, y_predict))\n",
    "    # print(classification_report(y_test,y_predict)) # we don't need this\n",
    "    print('The True Positive Rate (Recall/Sensitivity)is tpr = tp/(tp+fn): ', tpr)\n",
    "    print('The False Positive Rate (1-specification)is fpr = fp/(fp+tn): ', fpr)\n",
    "    print('The Precision (tp/(tp+fp)) is: ', precision)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_curves(model, X_test, y_test):\n",
    "    \n",
    "    # plot Precision Recall Curve\n",
    "    plt.figure(figsize=(8,6))\n",
    "    \n",
    "    # predict probabilities\n",
    "    probs = model.predict_proba(X_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    probs = probs[:, 1]\n",
    "    \n",
    "    # get predicted class value\n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    # calculate precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "    \n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0.8, 0.8], linestyle='--') \n",
    "    # plot the precision-recall curve for the model\n",
    "    plt.plot(recall, precision, color='darkorange', marker='.')\n",
    "    plt.xlabel('Recall (sensitivity, or True Positive Rate)')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision Recall Curve')\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investment_return_with_my_model(model, X_test, y_test):\n",
    "    \n",
    "    # get predicted class value\n",
    "    y_predict = model.predict(X_test)\n",
    "    # reshape\n",
    "    y_predict = y_predict.reshape((y_predict.shape[0], 1))\n",
    "    # put it into a dataframe\n",
    "    y_predict = pd.DataFrame(y_predict, index=range(0,len(y_predict)), columns=['loan_status_predicted'])\n",
    "    \n",
    "    # Join X_test and y_test using 'join' since they have the same index\n",
    "    loans_test = X_test.join(y_test)\n",
    "    \n",
    "    # Then join the test dataframe with y_predict; Since it is different index, I created a 'Join' column and then use 'merge'\n",
    "    loans_test['Join']=list(range(0,len(y_predict)))\n",
    "    y_predict['Join']=list(range(0,len(y_predict)))\n",
    "    # Merge test data with predicted data\n",
    "    loans_test_with_predict = pd.merge(loans_test, y_predict, on='Join')\n",
    "    \n",
    "    # filter the rows that are predicted as 1\n",
    "    predict_should_invest = loans_test_with_predict[loans_test_with_predict['loan_status_predicted']==1]\n",
    "    \n",
    "    # Among the loans predicted as 1, filter the rows thar are actually as 1\n",
    "    actual_should_invest = predict_should_invest[predict_should_invest['loan_status']==1]\n",
    "    \n",
    "    # calculate the mistake rate, this is the same as fpr\n",
    "    mistake_rate = (predict_should_invest.shape[0]-actual_should_invest.shape[0])/predict_should_invest.shape[0]\n",
    "    \n",
    "    # add a new column, indicating for each loan we invest 25 dollars\n",
    "    predict_should_invest['invest_amount'] = 25\n",
    "    \n",
    "    # add a new column, calculating interest earned from this loan by multiplying interest rate per loan with the amount invested per loan\n",
    "    predict_should_invest['interest_earned']=(predict_should_invest['int_rate']/100)*predict_should_invest['invest_amount']\n",
    "    \n",
    "    # sum the interest earned for all the loans we invested\n",
    "    total_interest = predict_should_invest['interest_earned'].sum()\n",
    "    \n",
    "    # calculate our investment return\n",
    "    investment_return = total_interest/(25*len(predict_should_invest))\n",
    "    print('The investment return with this model is: ', '{:.2%}'.format(investment_return))\n",
    "    \n",
    "    # calculate the return for the worse case, meaning if we lost all the money from the loans that are charged-off\n",
    "    #(including full amount of principal and interest, which is less likely), how much return we will get.\n",
    "    investment_return_with_maxlosss = (total_interest-(mistake_rate*(25*len(predict_should_invest))))/(25*len(predict_should_invest))\n",
    "    print('The investment return with this model for the worse case is: ', '{:.2%}'.format(investment_return_with_maxlosss))\n",
    "    print('\\n')\n",
    "#     print(predict_should_invest.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(loans_2007_2019.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select object columns\n",
    "object_columns = loans_2007_2019.select_dtypes(include=[\"object\"])\n",
    "\n",
    "object_columns.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode object columns to integer values and return a Dataframe containing the dummy columns.\n",
    "dummy_df = pd.get_dummies(loans_2007_2019[object_columns.columns], drop_first=True)\n",
    "\n",
    "# combine dummy column dataframe with original dataframe as column\n",
    "loans_2007_2019 = pd.concat([loans_2007_2019, dummy_df], axis=1)\n",
    "\n",
    "# drop original object columns\n",
    "loans_2007_2019 = loans_2007_2019.drop(object_columns.columns, axis=1)\n",
    "\n",
    "# review the result with 3 rows\n",
    "display(loans_2007_2019.head(1))\n",
    "\n",
    "print('The number of rows and columns in our machine learning model is : ', loans_2007_2019.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = loans_2007_2019.drop('loan_status', axis=1)\n",
    "\n",
    "target = loans_2007_2019['loan_status']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our model\n",
    "lr_mymodel_default = LogisticRegression().fit(X_train, y_train)\n",
    "# use my function\n",
    "my_metric(lr_mymodel_default, X_test, y_test)\n",
    "investment_return_with_my_model(lr_mymodel_default, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat model, set model parameter with balanced\n",
    "lr_mymodel_balanced = LogisticRegression(class_weight='balanced').fit(X_train, y_train)\n",
    "# use my function\n",
    "my_metric(lr_mymodel_balanced, X_test, y_test)\n",
    "investment_return_with_my_model(lr_mymodel_balanced, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_curves(lr_mymodel_balanced, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model, with balanced \n",
    "rf_balanced = RandomForestClassifier(class_weight=\"balanced\", random_state=1).fit(X_train, y_train)\n",
    "# use my function\n",
    "my_metric(rf_balanced, X_test, y_test)\n",
    "investment_return_with_my_model(rf_balanced, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set model parameter with different penalty\n",
    "for i in [6, 7, 8, 9, 10]:   \n",
    "    # creat our model\n",
    "    penalty = {0: i, 1: 1} \n",
    "    lrf_mymodel_penalty = LogisticRegression(class_weight=penalty).fit(X_train, y_train)\n",
    "    # use my function\n",
    "    my_metric(lrf_mymodel_penalty, X_test, y_test)  \n",
    "    investment_return_with_my_model(lrf_mymodel_penalty, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curve for the above model\n",
    "precision_recall_curves(lrf_mymodel_penalty, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
